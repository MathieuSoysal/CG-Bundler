use clap:: {Parser, Subcommand}; use std:: path:: PathBuf; use crate :: config:: CompressionConfig; use crate :: error:: Result; use crate :: rust_singler:: RustSingler; use crate :: discovery:: RecursiveFileDiscovery; use crate :: parser:: SynCodeParser; use crate :: minifier:: WhitespaceMinifier; use crate :: file_processor:: StandardFileProcessor; use crate :: reporter:: ConsoleErrorReporter; use crate :: performance:: MetricsCollector; #[derive(Parser, Debug)]#[command(name = "rust-singler")]#[command(version = "0.1.0")]#[command(about = "A Rust code compression tool that minifies Rust codebases into single-line format")]#[command(long_about = None)]pub struct CliArgs{#[command(subcommand)]pub command: Commands, #[arg(short, long, global = true)]pub verbose: bool, #[arg(long, global = true)]pub no_color: bool, #[arg(long, global = true)]pub no_metrics: bool,}#[derive(Subcommand, Debug)]pub enum Commands{Directory{#[arg(short, long)]input: PathBuf, #[arg(short, long)]output: PathBuf, #[arg(long, default_value_t = true)]preserve_strings: bool, #[arg(long)]keep_docs: bool, #[arg(long)]keep_tests: bool, #[arg(long)]multiline: bool,}, File{#[arg(short, long)]input: PathBuf, #[arg(short, long)]output: PathBuf, #[arg(long, default_value_t = true)]preserve_strings: bool, #[arg(long)]keep_docs: bool, #[arg(long)]keep_tests: bool, #[arg(long)]multiline: bool,},}pub struct CliApplication; impl CliApplication{pub fn new() -> Self{Self}pub fn run(& self, args: CliArgs) -> Result < () > {self.validate_arguments(& args)?; let config = self.create_config_from_args(& args); let mut singler = self.create_rust_singler(config,& args); match args.command{Commands:: Directory{ref input, ref output,..} => {if args.verbose{println!("ðŸ” Processing directory: {}", input.display()); println!("ðŸ“ Output file: {}", output.display());}singler.compress_directory(input, output)}Commands:: File{ref input, ref output,..} => {if args.verbose{println!("ðŸ” Processing file: {}", input.display()); println!("ðŸ“ Output file: {}", output.display());}singler.compress_file(input, output)}}}pub fn parse_arguments() -> CliArgs{CliArgs:: parse()}fn validate_arguments(& self, args:& CliArgs) -> Result < () > {match & args.command{Commands:: Directory{input,..} => {if!input.exists(){return Err(crate :: error:: ProcessingError:: InvalidPath(input.clone()));}if!input.is_dir(){return Err(crate :: error:: ProcessingError:: InvalidPath(input.clone()));}}Commands:: File{input,..} => {if!input.exists(){return Err(crate :: error:: ProcessingError:: FileNotFound(input.clone()));}if!input.is_file(){return Err(crate :: error:: ProcessingError:: InvalidPath(input.clone()));}if input.extension().and_then(| s | s.to_str())!= Some("rs"){return Err(crate :: error:: ProcessingError:: InvalidPath(input.clone()));}}}Ok(())}fn create_config_from_args(& self, args:& CliArgs) -> CompressionConfig{let (preserve_strings, keep_docs, keep_tests, multiline) = match & args.command{Commands:: Directory{preserve_strings, keep_docs, keep_tests, multiline,..} => {(* preserve_strings,* keep_docs,* keep_tests,* multiline)}Commands:: File{preserve_strings, keep_docs, keep_tests, multiline,..} => {(* preserve_strings,* keep_docs,* keep_tests,* multiline)}}; CompressionConfig{preserve_string_formatting: preserve_strings, remove_doc_comments:!keep_docs, remove_test_code:!keep_tests, output_single_line:!multiline,}}fn create_rust_singler(& self, config: CompressionConfig, args:& CliArgs) -> RustSingler{let file_discovery = Box:: new(RecursiveFileDiscovery:: new()); let code_parser = Box:: new(SynCodeParser:: new()); let code_minifier = Box:: new(WhitespaceMinifier:: new().with_string_preservation(config.preserve_string_formatting)); let file_processor = Box:: new(StandardFileProcessor:: new()); let error_reporter = Box:: new(ConsoleErrorReporter:: new().with_colors(!args.no_color)); let performance_tracker = Box:: new(MetricsCollector:: new().with_enabled(!args.no_metrics)); RustSingler:: new(file_discovery, code_parser, code_minifier, file_processor, error_reporter, performance_tracker, config,)}}impl Default for CliApplication{fn default() -> Self{Self:: new()}} #[derive(Debug, Clone)]pub struct CompressionConfig{pub preserve_string_formatting: bool, pub remove_doc_comments: bool, pub remove_test_code: bool, pub output_single_line: bool,}impl CompressionConfig{pub fn new() -> Self{Self:: default()}}impl Default for CompressionConfig{fn default() -> Self{Self{preserve_string_formatting: true, remove_doc_comments: true, remove_test_code: true, output_single_line: true,}}} use std:: path:: {Path, PathBuf}; use walkdir:: {DirEntry, WalkDir}; use crate :: error:: {ProcessingError, Result}; use crate :: traits:: FileDiscovery; pub struct RecursiveFileDiscovery; impl RecursiveFileDiscovery{pub fn new() -> Self{Self}fn is_rust_file(& self, path:& Path) -> bool{path.extension().and_then(| ext | ext.to_str()).map(| ext | ext == "rs").unwrap_or(false)}fn should_skip_directory(& self, path:& Path) -> bool{if let Some(name) = path.file_name().and_then(| n | n.to_str()){match name{"target" | ".git" | "node_modules" | ".cargo" => true, _ if name.starts_with('.') => true, _ => false,}}else {false}}#[allow(dead_code)]fn should_process_entry(& self, entry:& DirEntry) -> bool{let path = entry.path(); if path.is_dir(){!self.should_skip_directory(path)}else {self.is_rust_file(path)}}}impl FileDiscovery for RecursiveFileDiscovery{fn find_rust_files(& self, path:& Path) -> Result < Vec < PathBuf >> {if!path.exists(){return Err(ProcessingError:: FileNotFound(path.to_path_buf()));}let mut rust_files = Vec:: new(); if path.is_file(){if self.is_rust_file(path){rust_files.push(path.to_path_buf());}return Ok(rust_files);}for entry in WalkDir:: new(path).into_iter().filter_entry(| e | {if e.path() == path{return true;}if e.path().is_dir(){return!self.should_skip_directory(e.path());}true}){let entry = entry.map_err(| e | ProcessingError:: IoError(e.into()))?; let entry_path = entry.path(); if entry_path.is_file() && self.is_rust_file(entry_path){rust_files.push(entry_path.to_path_buf());}}rust_files.sort(); Ok(rust_files)}}impl Default for RecursiveFileDiscovery{fn default() -> Self{Self:: new()}} use std:: path:: PathBuf; use thiserror:: Error; #[derive(Error, Debug)]pub enum ProcessingError{#[error("File not found: {0}")]FileNotFound(PathBuf), #[error("Parse error: {0}")]ParseError(String), #[error("IO error: {0}")]IoError(#[from]std:: io:: Error), #[error("Compression error: {0}")]CompressionError(String), #[error("Invalid input path: {0}")]InvalidPath(PathBuf), #[error("Output directory creation failed: {0}")]OutputDirectoryError(String),}pub type Result < T >= std:: result:: Result < T, ProcessingError >; use std:: fs; use std:: path:: Path; use crate :: error:: {ProcessingError, Result}; use crate :: traits:: FileProcessor; pub struct StandardFileProcessor; impl StandardFileProcessor{pub fn new() -> Self{Self}fn ensure_output_directory(& self, path:& Path) -> Result < () > {if let Some(parent) = path.parent(){if!parent.exists(){fs:: create_dir_all(parent).map_err(| e | ProcessingError:: OutputDirectoryError(format!("Failed to create directory {}: {}", parent.display(), e)))?;}}Ok(())}}impl FileProcessor for StandardFileProcessor{fn read_file(& self, path:& Path) -> Result < String > {if!path.exists(){return Err(ProcessingError:: FileNotFound(path.to_path_buf()));}fs:: read_to_string(path).map_err(| e | ProcessingError:: IoError(e))}fn write_file(& self, path:& Path, content:& str) -> Result < () > {self.ensure_output_directory(path)?; fs:: write(path, content).map_err(| e | ProcessingError:: IoError(e))}}impl Default for StandardFileProcessor{fn default() -> Self{Self:: new()}} pub mod cli; pub mod config; pub mod discovery; pub mod error; pub mod file_processor; pub mod minifier; pub mod parser; pub mod performance; pub mod reporter; pub mod rust_singler; pub mod syntax_tree; pub mod traits; pub use error:: {ProcessingError, Result}; pub use config:: CompressionConfig; pub use rust_singler:: RustSingler; use rust_singler:: cli:: CliApplication; use std:: process; fn main(){let app = CliApplication:: new(); let args = CliApplication:: parse_arguments(); if let Err(e) = app.run(args){eprintln!("âŒ Error: {}", e); process:: exit(1);}} use crate :: error:: Result; use crate :: syntax_tree:: SyntaxTree; use crate :: traits:: CodeMinifier; use proc_macro2:: {Spacing, TokenStream, TokenTree}; pub struct WhitespaceMinifier{preserve_string_literals: bool,}impl WhitespaceMinifier{pub fn new() -> Self{Self{preserve_string_literals: true,}}pub fn with_string_preservation(mut self, preserve: bool) -> Self{self.preserve_string_literals = preserve; self}}impl CodeMinifier for WhitespaceMinifier{fn minify(& self, tree:& SyntaxTree) -> Result < String > {let tokens = tree.to_token_stream(); self.compress_token_stream(& tokens)}fn compress_to_single_line(& self, code:& str) -> Result < String > {let tokens: TokenStream = code.parse().map_err(| e | {crate :: error:: ProcessingError:: IoError(std:: io:: Error:: new(std:: io:: ErrorKind:: InvalidData, format!("Failed to parse Rust code: {}", e)))})?; self.compress_token_stream(& tokens)}}impl Default for WhitespaceMinifier{fn default() -> Self{Self:: new()}}impl WhitespaceMinifier{fn compress_token_stream(& self, tokens:& TokenStream) -> Result < String > {let mut result = String:: new(); let mut prev_token_type = TokenType:: None; for token in tokens.clone(){let current_token_type = self.get_token_type(& token); if self.needs_separator(prev_token_type, current_token_type,& result){result.push(' ');}self.append_token(& mut result,& token)?; prev_token_type = current_token_type;}self.remove_doc_attributes(& result)}fn remove_doc_attributes(& self, input:& str) -> Result < String > {let mut result = String:: new(); let mut i = 0; let chars: Vec < char >= input.chars().collect(); while i < chars.len(){if chars[i] == '#'{if let Some(end_pos) = self.find_doc_attribute_end_from_pos(& chars, i){i = end_pos + 1; continue;}}result.push(chars[i]); i += 1;}Ok(result)}fn find_doc_attribute_end_from_pos(& self, chars:& [char], start: usize) -> Option < usize > {if start >= chars.len() || chars[start]!= '#'{return None;}let mut i = start + 1; while i < chars.len() && chars[i].is_whitespace(){i += 1;}if i >= chars.len() || chars[i]!= '['{return None;}i += 1; while i < chars.len() && chars[i].is_whitespace(){i += 1;}if i + 3 > chars.len() || chars[i..i + 3]!= ['d', 'o', 'c']{return None;}i += 3; while i < chars.len() && chars[i].is_whitespace(){i += 1;}if i >= chars.len() || chars[i]!= '='{return None;}i += 1; let mut bracket_depth = 0; let mut in_string = false; let mut escape_next = false; while i < chars.len(){let ch = chars[i]; if escape_next{escape_next = false; i += 1; continue;}match ch{'\\' if in_string => escape_next = true, '"' => in_string =!in_string, '[' if!in_string => bracket_depth += 1, ']' if!in_string => {if bracket_depth == 0{return Some(i);}bracket_depth -= 1;}_ => {}}i += 1;}None}fn get_token_type(& self, token:& TokenTree) -> TokenType{match token{TokenTree:: Group(_) => TokenType:: Group, TokenTree:: Ident(_) => TokenType:: Ident, TokenTree:: Punct(punct) => {match punct.as_char(){'(' | '[' | '{' => TokenType:: OpenDelim, ')' | ']' | '}' => TokenType:: CloseDelim, ',' | ';' => TokenType:: Separator, ':' => if punct.spacing() == Spacing:: Joint{TokenType:: DoubleColon}else {TokenType:: Colon}, '!' => TokenType:: Bang, '=' | '+' | '-' | '*' | '/' | '%' | '&' | '|' | '^' | '<' | '>' => TokenType:: Operator, '.' => TokenType:: Dot, _ => TokenType:: Punct,}}TokenTree:: Literal(_) => TokenType:: Literal,}}fn needs_separator(& self, prev: TokenType, current: TokenType, prev_text:& str) -> bool{use TokenType::*; if prev == None || prev_text.is_empty(){return false;}match (prev, current){(_, OpenDelim) | (_, Separator) | (_, CloseDelim) | (_, Dot) | (_, Bang) => false, (OpenDelim, _) | (Dot, _) | (DoubleColon, _) | (Bang, _) => false, (Ident, Ident) | (Ident, Literal) | (Literal, Ident) | (Literal, Literal) => true, (_, Operator) | (Operator, _) => {if current == Operator{!matches!(prev, OpenDelim | Separator | Operator | Colon)}else {true}}(Separator, _) | (Colon, _) => true, (Ident, _)if self.is_keyword_context(prev_text) => true, _ => false,}}fn is_keyword_context(& self, text:& str) -> bool{const KEYWORDS:& [& str] =& ["as", "break", "const", "continue", "crate", "else", "enum", "extern", "false", "fn", "for", "if", "impl", "in", "let", "loop", "match", "mod", "move", "mut", "pub", "ref", "return", "static", "struct", "super", "trait", "true", "type", "unsafe", "use", "where", "while", "async", "await", "dyn", "union"]; for keyword in KEYWORDS{if text.ends_with(keyword){let start_idx = text.len() - keyword.len(); if start_idx == 0{return true;}if let Some(prev_char) = text.chars().nth(start_idx - 1){if!prev_char.is_alphanumeric() && prev_char!= '_'{return true;}}}}false}fn append_token(& self, result:& mut String, token:& TokenTree) -> Result < () > {match token{TokenTree:: Group(group) => {let open_delim = match group.delimiter(){proc_macro2:: Delimiter:: Parenthesis => "(", proc_macro2:: Delimiter:: Brace => "{", proc_macro2:: Delimiter:: Bracket => "[", proc_macro2:: Delimiter:: None => "",}; result.push_str(open_delim); let inner = self.compress_token_stream(& group.stream())?; result.push_str(& inner); let close_delim = match group.delimiter(){proc_macro2:: Delimiter:: Parenthesis => ")", proc_macro2:: Delimiter:: Brace => "}", proc_macro2:: Delimiter:: Bracket => "]", proc_macro2:: Delimiter:: None => "",}; result.push_str(close_delim);}TokenTree:: Ident(ident) => {result.push_str(& ident.to_string());}TokenTree:: Punct(punct) => {result.push(punct.as_char());}TokenTree:: Literal(literal) => {let lit_str = literal.to_string(); if self.preserve_string_literals{result.push_str(& lit_str);}else {result.push_str(& lit_str);}}}Ok(())}}#[derive(Debug, Clone, Copy, PartialEq)]enum TokenType{None, Group, Ident, Literal, OpenDelim, CloseDelim, Separator, Colon, DoubleColon, Bang, Operator, Dot, Punct,} use syn:: {parse_file, Attribute, Item, ItemFn, ItemMod, Meta, AttrStyle, visit_mut:: {self, VisitMut}}; use crate :: error:: {ProcessingError, Result}; use crate :: syntax_tree:: SyntaxTree; use crate :: traits:: CodeParser; pub struct SynCodeParser; impl SynCodeParser{pub fn new() -> Self{Self}fn remove_comments(& self, tree:& mut SyntaxTree){let mut visitor = CommentRemover; visitor.visit_file_mut(tree.file_mut());}fn remove_test_code(& self, tree:& mut SyntaxTree){let items = tree.items_mut(); items.retain(| item |!self.is_test_item(item)); let mut visitor = TestCodeRemover; visitor.visit_file_mut(tree.file_mut());}fn remove_cfg_test_attributes(& self, tree:& mut SyntaxTree){let mut visitor = CfgTestRemover; visitor.visit_file_mut(tree.file_mut());}fn is_test_item(& self, item:& Item) -> bool{match item{Item:: Fn(func) => self.is_test_function(func), Item:: Mod(module) => self.is_test_module(module), _ => false,}}fn is_test_function(& self, func:& ItemFn) -> bool{func.attrs.iter().any(| attr | self.is_test_attribute(attr))}fn is_test_module(& self, module:& ItemMod) -> bool{module.attrs.iter().any(| attr | self.is_cfg_test_attribute(attr))}fn is_test_attribute(& self, attr:& Attribute) -> bool{if let Meta:: Path(path) =& attr.meta{path.is_ident("test")}else {false}}fn is_cfg_test_attribute(& self, attr:& Attribute) -> bool{if let Meta:: List(list) =& attr.meta{if list.path.is_ident("cfg"){return list.tokens.to_string().contains("test");}}false}#[allow(dead_code)]fn is_doc_comment_attribute(& self, attr:& Attribute) -> bool{matches!(attr.style, AttrStyle:: Outer) && attr.path().is_ident("doc")}}impl CodeParser for SynCodeParser{fn parse(& self, content:& str) -> Result < SyntaxTree > {let file = parse_file(content).map_err(| e | ProcessingError:: ParseError(e.to_string()))?; Ok(SyntaxTree:: new(file))}fn remove_unwanted_elements(& self, tree:& mut SyntaxTree) -> Result < () > {self.remove_test_code(tree); self.remove_comments(tree); self.remove_cfg_test_attributes(tree); Ok(())}}impl Default for SynCodeParser{fn default() -> Self{Self:: new()}}struct CommentRemover; impl VisitMut for CommentRemover{fn visit_file_mut(& mut self, file:& mut syn:: File){file.attrs.retain(| attr |!self.is_doc_attribute(attr)); visit_mut:: visit_file_mut(self, file);}fn visit_item_mut(& mut self, item:& mut Item){match item{Item:: Fn(func) => {func.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Struct(s) => {s.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Enum(e) => {e.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Mod(m) => {m.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Use(u) => {u.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Type(t) => {t.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Const(c) => {c.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Static(s) => {s.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Trait(t) => {t.attrs.retain(| attr |!self.is_doc_attribute(attr));}Item:: Impl(i) => {i.attrs.retain(| attr |!self.is_doc_attribute(attr));}_ => {}}visit_mut:: visit_item_mut(self, item);}fn visit_field_mut(& mut self, field:& mut syn:: Field){field.attrs.retain(| attr |!self.is_doc_attribute(attr)); visit_mut:: visit_field_mut(self, field);}fn visit_variant_mut(& mut self, variant:& mut syn:: Variant){variant.attrs.retain(| attr |!self.is_doc_attribute(attr)); visit_mut:: visit_variant_mut(self, variant);}}impl CommentRemover{fn is_doc_attribute(& self, attr:& Attribute) -> bool{if attr.path().is_ident("doc"){return true;}if let AttrStyle:: Outer = attr.style{if attr.path().is_ident("doc"){return true;}}if let AttrStyle:: Inner(_) = attr.style{if attr.path().is_ident("doc"){return true;}}false}}struct TestCodeRemover; impl VisitMut for TestCodeRemover{fn visit_item_mod_mut(& mut self, module:& mut ItemMod){if let Some((_, items)) =& mut module.content{items.retain(| item | {match item{Item:: Fn(func) =>!func.attrs.iter().any(| attr | {if let Meta:: Path(path) =& attr.meta{path.is_ident("test") || path.is_ident("bench")}else {false}}), _ => true,}});}visit_mut:: visit_item_mod_mut(self, module);}}struct CfgTestRemover; impl VisitMut for CfgTestRemover{fn visit_item_mut(& mut self, item:& mut Item){match item{Item:: Fn(func) => {func.attrs.retain(| attr |!is_cfg_test_attr(attr));}Item:: Mod(m) => {m.attrs.retain(| attr |!is_cfg_test_attr(attr));}Item:: Struct(s) => {s.attrs.retain(| attr |!is_cfg_test_attr(attr));}Item:: Enum(e) => {e.attrs.retain(| attr |!is_cfg_test_attr(attr));}_ => {}}visit_mut:: visit_item_mut(self, item);}}fn is_cfg_test_attr(attr:& Attribute) -> bool{if let Meta:: List(list) =& attr.meta{if list.path.is_ident("cfg"){return list.tokens.to_string().contains("test");}}false} use std:: collections:: HashMap; use std:: time:: {Duration, Instant}; use crate :: traits:: PerformanceTracker; pub struct MetricsCollector{timers: HashMap < String, Instant >, metrics: HashMap < String, Duration >, enabled: bool,}impl MetricsCollector{pub fn new() -> Self{Self{timers: HashMap:: new(), metrics: HashMap:: new(), enabled: true,}}pub fn with_enabled(mut self, enabled: bool) -> Self{self.enabled = enabled; self}pub fn get_total_processing_time(& self) -> Duration{self.metrics.values().sum()}pub fn get_operation_time(& self, operation:& str) -> Option < Duration > {self.metrics.get(operation).copied()}pub fn get_all_metrics(& self) ->& HashMap < String, Duration > {& self.metrics}pub fn clear(& mut self){self.timers.clear(); self.metrics.clear();}}impl PerformanceTracker for MetricsCollector{fn start_timer(& mut self, operation:& str){if self.enabled{self.timers.insert(operation.to_string(), Instant:: now());}}fn end_timer(& mut self, operation:& str){if!self.enabled{return;}if let Some(start_time) = self.timers.remove(operation){let duration = start_time.elapsed(); self.metrics.insert(operation.to_string(), duration);}}fn report_metrics(& self){if!self.enabled || self.metrics.is_empty(){return;}println!("\nðŸ“Š Performance Metrics:"); println!("{}", "â”€".repeat(50)); let mut operations: Vec < _ >= self.metrics.iter().collect(); operations.sort_by_key(| (_, duration) |* duration); operations.reverse(); for(operation, duration)in operations{println!("  {:<30} {:>8.2}ms", operation, duration.as_secs_f64() * 1000.0);}let total = self.get_total_processing_time(); println!("{}", "â”€".repeat(50)); println!("  {:<30} {:>8.2}ms", "Total", total.as_secs_f64() * 1000.0);}}impl Default for MetricsCollector{fn default() -> Self{Self:: new()}}pub struct NoOpPerformanceTracker; impl PerformanceTracker for NoOpPerformanceTracker{fn start_timer(& mut self, _operation:& str){}fn end_timer(& mut self, _operation:& str){}fn report_metrics(& self){}} use colored:: Colorize; use crate :: error:: ProcessingError; use crate :: traits:: ErrorReporter; pub struct ConsoleErrorReporter{use_colors: bool,}impl ConsoleErrorReporter{pub fn new() -> Self{Self{use_colors: true,}}pub fn with_colors(mut self, use_colors: bool) -> Self{self.use_colors = use_colors; self}fn format_with_colors(& self, message:& str, color_type: ColorType) -> String{if!self.use_colors{return message.to_string();}match color_type{ColorType:: Error => message.red().bold().to_string(), ColorType:: Warning => message.yellow().bold().to_string(), ColorType:: Info => message.blue().to_string(), ColorType:: Success => message.green().to_string(), ColorType:: Path => message.cyan().to_string(),}}}impl ErrorReporter for ConsoleErrorReporter{fn report_error(& self, error:& ProcessingError){let message = self.format_error_message(error); eprintln!("{}", message);}fn format_error_message(& self, error:& ProcessingError) -> String{match error{ProcessingError:: FileNotFound(path) => {format!("{}: File not found: {}", self.format_with_colors("Error", ColorType:: Error), self.format_with_colors(& path.display().to_string(), ColorType:: Path))}ProcessingError:: ParseError(msg) => {format!("{}: Failed to parse Rust code: {}", self.format_with_colors("Parse Error", ColorType:: Error), msg)}ProcessingError:: IoError(io_err) => {format!("{}: I/O operation failed: {}", self.format_with_colors("I/O Error", ColorType:: Error), io_err)}ProcessingError:: CompressionError(msg) => {format!("{}: Code compression failed: {}", self.format_with_colors("Compression Error", ColorType:: Error), msg)}ProcessingError:: InvalidPath(path) => {format!("{}: Invalid path specified: {}", self.format_with_colors("Invalid Path", ColorType:: Error), self.format_with_colors(& path.display().to_string(), ColorType:: Path))}ProcessingError:: OutputDirectoryError(msg) => {format!("{}: Failed to create output directory: {}", self.format_with_colors("Directory Error", ColorType:: Error), msg)}}}}impl Default for ConsoleErrorReporter{fn default() -> Self{Self:: new()}}#[derive(Debug, Clone, Copy)]#[allow(dead_code)]enum ColorType{Error, Warning, Info, Success, Path,}pub struct SilentErrorReporter; impl ErrorReporter for SilentErrorReporter{fn report_error(& self, _error:& ProcessingError){}fn format_error_message(& self, error:& ProcessingError) -> String{error.to_string()}} use std:: path:: Path; use crate :: config:: CompressionConfig; use crate :: error:: {ProcessingError, Result}; use crate :: traits:: {FileDiscovery, CodeParser, CodeMinifier, FileProcessor, ErrorReporter, PerformanceTracker}; pub struct RustSingler{file_discovery: Box < dyn FileDiscovery >, code_parser: Box < dyn CodeParser >, code_minifier: Box < dyn CodeMinifier >, file_processor: Box < dyn FileProcessor >, error_reporter: Box < dyn ErrorReporter >, performance_tracker: Box < dyn PerformanceTracker >, config: CompressionConfig,}impl RustSingler{pub fn new(file_discovery: Box < dyn FileDiscovery >, code_parser: Box < dyn CodeParser >, code_minifier: Box < dyn CodeMinifier >, file_processor: Box < dyn FileProcessor >, error_reporter: Box < dyn ErrorReporter >, performance_tracker: Box < dyn PerformanceTracker >, config: CompressionConfig,) -> Self{Self{file_discovery, code_parser, code_minifier, file_processor, error_reporter, performance_tracker, config,}}pub fn compress_directory(& mut self, input_path:& Path, output_path:& Path) -> Result < () > {self.performance_tracker.start_timer("total_compression"); self.performance_tracker.start_timer("file_discovery"); let rust_files = self.file_discovery.find_rust_files(input_path).map_err(| e | {self.error_reporter.report_error(& e); e})?; self.performance_tracker.end_timer("file_discovery"); if rust_files.is_empty(){let error = ProcessingError:: FileNotFound(input_path.to_path_buf()); self.error_reporter.report_error(& error); return Err(error);}println!("ðŸ“ Found {} Rust files to process", rust_files.len()); self.performance_tracker.start_timer("processing_all_files"); let mut all_compressed_code = String:: new(); let mut processed_count = 0; for file_path in & rust_files{match self.process_single_file(file_path){Ok(compressed) => {if!all_compressed_code.is_empty(){all_compressed_code.push(' ');}all_compressed_code.push_str(& compressed); processed_count += 1;}Err(e) => {self.error_reporter.report_error(& e);}}}self.performance_tracker.end_timer("processing_all_files"); if processed_count == 0{let error = ProcessingError:: CompressionError("No files were successfully processed".to_string()); self.error_reporter.report_error(& error); return Err(error);}self.performance_tracker.start_timer("writing_output"); self.file_processor.write_file(output_path,& all_compressed_code).map_err(| e | {self.error_reporter.report_error(& e); e})?; self.performance_tracker.end_timer("writing_output"); self.performance_tracker.end_timer("total_compression"); println!("âœ… Successfully compressed {} files to {}", processed_count, output_path.display()); self.performance_tracker.report_metrics(); Ok(())}pub fn compress_file(& mut self, input_file:& Path, output_file:& Path) -> Result < () > {self.performance_tracker.start_timer("single_file_compression"); let compressed_code = self.process_single_file(input_file).map_err(| e | {self.error_reporter.report_error(& e); e})?; self.file_processor.write_file(output_file,& compressed_code).map_err(| e | {self.error_reporter.report_error(& e); e})?; self.performance_tracker.end_timer("single_file_compression"); println!("âœ… Successfully compressed {} to {}", input_file.display(), output_file.display()); self.performance_tracker.report_metrics(); Ok(())}fn process_single_file(& mut self, file_path:& Path) -> Result < String > {self.performance_tracker.start_timer("read_file"); let content = self.file_processor.read_file(file_path)?; self.performance_tracker.end_timer("read_file"); self.performance_tracker.start_timer("parse_file"); let mut syntax_tree = self.code_parser.parse(& content)?; self.performance_tracker.end_timer("parse_file"); self.performance_tracker.start_timer("remove_unwanted"); self.code_parser.remove_unwanted_elements(& mut syntax_tree)?; self.performance_tracker.end_timer("remove_unwanted"); self.performance_tracker.start_timer("minify_code"); let compressed = self.code_minifier.minify(& syntax_tree)?; self.performance_tracker.end_timer("minify_code"); Ok(compressed)}pub fn config(& self) ->& CompressionConfig{& self.config}pub fn set_config(& mut self, config: CompressionConfig){self.config = config;}} use syn:: {File, Item}; use proc_macro2:: TokenStream; use quote:: ToTokens; #[derive(Debug, Clone)]pub struct SyntaxTree{file: File,}impl SyntaxTree{pub fn new(file: File) -> Self{Self{file}}pub fn empty() -> Self{Self{file: File{shebang: None, attrs: Vec:: new(), items: Vec:: new(),}}}pub fn items(& self) ->& Vec < Item > {& self.file.items}pub fn items_mut(& mut self) ->& mut Vec < Item > {& mut self.file.items}pub fn add_item(& mut self, item: Item){self.file.items.push(item);}pub fn remove_item(& mut self, index: usize) -> Option < Item > {if index < self.file.items.len(){Some(self.file.items.remove(index))}else {None}}pub fn to_token_stream(& self) -> TokenStream{self.file.to_token_stream()}pub fn file(& self) ->& File{& self.file}pub fn file_mut(& mut self) ->& mut File{& mut self.file}}impl From < File > for SyntaxTree{fn from(file: File) -> Self{Self:: new(file)}}impl Into < File > for SyntaxTree{fn into(self) -> File{self.file}} use std:: path:: {Path, PathBuf}; use crate :: error:: Result; use crate :: syntax_tree:: SyntaxTree; pub trait FileDiscovery{fn find_rust_files(& self, path:& Path) -> Result < Vec < PathBuf >>;}pub trait CodeParser{fn parse(& self, content:& str) -> Result < SyntaxTree >; fn remove_unwanted_elements(& self, tree:& mut SyntaxTree) -> Result < () >;}pub trait CodeMinifier{fn minify(& self, tree:& SyntaxTree) -> Result < String >; fn compress_to_single_line(& self, code:& str) -> Result < String >;}pub trait FileProcessor{fn read_file(& self, path:& Path) -> Result < String >; fn write_file(& self, path:& Path, content:& str) -> Result < () >;}pub trait ErrorReporter{fn report_error(& self, error:& crate :: error:: ProcessingError); fn format_error_message(& self, error:& crate :: error:: ProcessingError) -> String;}pub trait PerformanceTracker{fn start_timer(& mut self, operation:& str); fn end_timer(& mut self, operation:& str); fn report_metrics(& self);}